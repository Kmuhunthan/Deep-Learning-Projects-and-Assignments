{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUN-XSl6sUBW",
        "outputId": "cd1bd127-290d-41e5-f1b1-72a992d851c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import Callback\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "!pip install keras-lookahead\n",
        "from keras_lookahead import Lookahead\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-lookahead in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-lookahead) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-lookahead) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-lookahead) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-lookahead) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-lookahead) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-lookahead) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CxQhkRuamW",
        "outputId": "de1dc636-1435-4313-f4cf-ccb63abfb2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "no_of_classes = len(np.unique(y_train))\n",
        "print(no_of_classes)\n",
        "\n",
        "#Data transformation \n",
        "#Normalising the pixels\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "\n",
        "\n",
        "#Split the training and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "\n",
        "#Encoding the y_train, y_val and y_test\n",
        "y_train=to_categorical(y_train,10)\n",
        "y_val=to_categorical(y_val,10)\n",
        "y_test=to_categorical(y_test,10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n",
            "10\n",
            "(35000, 32, 32, 3)\n",
            "(35000, 1)\n",
            "(15000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g_QE8Buv6yQ",
        "outputId": "3e33fc23-7d28-4351-b205-913fd18cf22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
        "\n",
        "#initialize lookahead\n",
        "lk = Lookahead(adam, sync_period=5, slow_step=0.5, name = 'Lookahead')\n",
        "#opt_rms = keras.optimizers.RMSprop(lr=0.0003,decay=1e-6)\n",
        "\n",
        "model6 = Sequential()\n",
        "model6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D(pool_size=2))\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D(pool_size=2))\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D(pool_size=2))\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(MaxPooling2D(pool_size=2))\n",
        "model6.add(Dropout(0.2))\n",
        "\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model6.add(BatchNormalization())\n",
        "model6.add(Dropout(0.3))\n",
        "model6.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model6.compile(optimizer = lk.optimizer, loss ='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model6.summary()\n",
        "\n",
        "#Data augmentation\n",
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False)\n",
        "\n",
        "it_train = datagen.flow(X_train,y_train)\n",
        "it_val = datagen.flow(X_val,y_val)\n",
        "steps = int(X_train.shape[0] / 64)\n",
        "\n",
        "history6=model6.fit_generator(it_train,\n",
        "                              epochs=100,\n",
        "                              steps_per_epoch=steps,\n",
        "                              validation_data=(it_val),\n",
        "                              validation_steps = 100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,309,098\n",
            "Trainable params: 1,306,922\n",
            "Non-trainable params: 2,176\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "546/546 [==============================] - 11s 19ms/step - loss: 1.9203 - accuracy: 0.3313 - val_loss: 1.6000 - val_accuracy: 0.4253\n",
            "Epoch 2/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 1.4756 - accuracy: 0.4687 - val_loss: 1.3020 - val_accuracy: 0.5387\n",
            "Epoch 3/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 1.2960 - accuracy: 0.5377 - val_loss: 1.2019 - val_accuracy: 0.5759\n",
            "Epoch 4/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 1.1597 - accuracy: 0.5902 - val_loss: 1.0552 - val_accuracy: 0.6247\n",
            "Epoch 5/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 1.0564 - accuracy: 0.6299 - val_loss: 0.9731 - val_accuracy: 0.6612\n",
            "Epoch 6/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 1.0021 - accuracy: 0.6521 - val_loss: 0.9268 - val_accuracy: 0.6650\n",
            "Epoch 7/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.9449 - accuracy: 0.6739 - val_loss: 0.9674 - val_accuracy: 0.6497\n",
            "Epoch 8/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.8945 - accuracy: 0.6933 - val_loss: 0.8005 - val_accuracy: 0.7203\n",
            "Epoch 9/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.8651 - accuracy: 0.6992 - val_loss: 0.7707 - val_accuracy: 0.7309\n",
            "Epoch 10/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.8318 - accuracy: 0.7129 - val_loss: 0.7940 - val_accuracy: 0.7244\n",
            "Epoch 11/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.7852 - accuracy: 0.7296 - val_loss: 0.7326 - val_accuracy: 0.7509\n",
            "Epoch 12/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.7688 - accuracy: 0.7381 - val_loss: 0.8294 - val_accuracy: 0.7237\n",
            "Epoch 13/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.7445 - accuracy: 0.7465 - val_loss: 0.7215 - val_accuracy: 0.7487\n",
            "Epoch 14/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.7234 - accuracy: 0.7518 - val_loss: 0.6537 - val_accuracy: 0.7741\n",
            "Epoch 15/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.7061 - accuracy: 0.7640 - val_loss: 0.6786 - val_accuracy: 0.7716\n",
            "Epoch 16/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6849 - accuracy: 0.7652 - val_loss: 0.6881 - val_accuracy: 0.7606\n",
            "Epoch 17/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6534 - accuracy: 0.7751 - val_loss: 0.6796 - val_accuracy: 0.7613\n",
            "Epoch 18/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6718 - accuracy: 0.7734 - val_loss: 0.6234 - val_accuracy: 0.7850\n",
            "Epoch 19/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6384 - accuracy: 0.7817 - val_loss: 0.6097 - val_accuracy: 0.7875\n",
            "Epoch 20/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6247 - accuracy: 0.7844 - val_loss: 0.6100 - val_accuracy: 0.7903\n",
            "Epoch 21/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.6119 - accuracy: 0.7940 - val_loss: 0.6163 - val_accuracy: 0.7931\n",
            "Epoch 22/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5952 - accuracy: 0.7965 - val_loss: 0.6130 - val_accuracy: 0.7941\n",
            "Epoch 23/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5912 - accuracy: 0.7972 - val_loss: 0.5888 - val_accuracy: 0.8012\n",
            "Epoch 24/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5812 - accuracy: 0.7997 - val_loss: 0.5994 - val_accuracy: 0.7987\n",
            "Epoch 25/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5684 - accuracy: 0.8079 - val_loss: 0.5573 - val_accuracy: 0.8194\n",
            "Epoch 26/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5544 - accuracy: 0.8135 - val_loss: 0.5630 - val_accuracy: 0.8097\n",
            "Epoch 27/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5572 - accuracy: 0.8112 - val_loss: 0.5702 - val_accuracy: 0.8022\n",
            "Epoch 28/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5486 - accuracy: 0.8140 - val_loss: 0.5765 - val_accuracy: 0.8066\n",
            "Epoch 29/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5443 - accuracy: 0.8142 - val_loss: 0.5314 - val_accuracy: 0.8153\n",
            "Epoch 30/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5293 - accuracy: 0.8195 - val_loss: 0.5666 - val_accuracy: 0.8009\n",
            "Epoch 31/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5240 - accuracy: 0.8205 - val_loss: 0.6125 - val_accuracy: 0.7816\n",
            "Epoch 32/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5137 - accuracy: 0.8221 - val_loss: 0.5390 - val_accuracy: 0.8166\n",
            "Epoch 33/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.5157 - accuracy: 0.8234 - val_loss: 0.5096 - val_accuracy: 0.8288\n",
            "Epoch 34/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4946 - accuracy: 0.8349 - val_loss: 0.5440 - val_accuracy: 0.8134\n",
            "Epoch 35/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4948 - accuracy: 0.8309 - val_loss: 0.4946 - val_accuracy: 0.8366\n",
            "Epoch 36/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4900 - accuracy: 0.8332 - val_loss: 0.4544 - val_accuracy: 0.8428\n",
            "Epoch 37/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4756 - accuracy: 0.8386 - val_loss: 0.5476 - val_accuracy: 0.8216\n",
            "Epoch 38/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4845 - accuracy: 0.8365 - val_loss: 0.6203 - val_accuracy: 0.7909\n",
            "Epoch 39/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4734 - accuracy: 0.8389 - val_loss: 0.5113 - val_accuracy: 0.8291\n",
            "Epoch 40/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4645 - accuracy: 0.8413 - val_loss: 0.4849 - val_accuracy: 0.8425\n",
            "Epoch 41/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4516 - accuracy: 0.8491 - val_loss: 0.5117 - val_accuracy: 0.8231\n",
            "Epoch 42/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4461 - accuracy: 0.8467 - val_loss: 0.5109 - val_accuracy: 0.8281\n",
            "Epoch 43/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4533 - accuracy: 0.8461 - val_loss: 0.4610 - val_accuracy: 0.8466\n",
            "Epoch 44/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4480 - accuracy: 0.8472 - val_loss: 0.4755 - val_accuracy: 0.8400\n",
            "Epoch 45/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4401 - accuracy: 0.8502 - val_loss: 0.4630 - val_accuracy: 0.8428\n",
            "Epoch 46/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4367 - accuracy: 0.8530 - val_loss: 0.4822 - val_accuracy: 0.8366\n",
            "Epoch 47/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4296 - accuracy: 0.8542 - val_loss: 0.4878 - val_accuracy: 0.8409\n",
            "Epoch 48/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4373 - accuracy: 0.8495 - val_loss: 0.4666 - val_accuracy: 0.8403\n",
            "Epoch 49/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4272 - accuracy: 0.8539 - val_loss: 0.4831 - val_accuracy: 0.8350\n",
            "Epoch 50/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4201 - accuracy: 0.8578 - val_loss: 0.4783 - val_accuracy: 0.8353\n",
            "Epoch 51/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4164 - accuracy: 0.8575 - val_loss: 0.5022 - val_accuracy: 0.8344\n",
            "Epoch 52/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4142 - accuracy: 0.8558 - val_loss: 0.4433 - val_accuracy: 0.8497\n",
            "Epoch 53/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4203 - accuracy: 0.8591 - val_loss: 0.4413 - val_accuracy: 0.8587\n",
            "Epoch 54/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4017 - accuracy: 0.8609 - val_loss: 0.4386 - val_accuracy: 0.8556\n",
            "Epoch 55/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.4042 - accuracy: 0.8614 - val_loss: 0.4792 - val_accuracy: 0.8384\n",
            "Epoch 56/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3947 - accuracy: 0.8669 - val_loss: 0.4157 - val_accuracy: 0.8616\n",
            "Epoch 57/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3940 - accuracy: 0.8646 - val_loss: 0.5066 - val_accuracy: 0.8278\n",
            "Epoch 58/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3946 - accuracy: 0.8636 - val_loss: 0.5131 - val_accuracy: 0.8325\n",
            "Epoch 59/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3888 - accuracy: 0.8704 - val_loss: 0.4666 - val_accuracy: 0.8444\n",
            "Epoch 60/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3954 - accuracy: 0.8663 - val_loss: 0.4512 - val_accuracy: 0.8472\n",
            "Epoch 61/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3751 - accuracy: 0.8729 - val_loss: 0.4330 - val_accuracy: 0.8569\n",
            "Epoch 62/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3848 - accuracy: 0.8688 - val_loss: 0.4231 - val_accuracy: 0.8603\n",
            "Epoch 63/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3745 - accuracy: 0.8710 - val_loss: 0.5270 - val_accuracy: 0.8259\n",
            "Epoch 64/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3739 - accuracy: 0.8733 - val_loss: 0.4000 - val_accuracy: 0.8672\n",
            "Epoch 65/100\n",
            "546/546 [==============================] - 10s 18ms/step - loss: 0.3702 - accuracy: 0.8753 - val_loss: 0.4362 - val_accuracy: 0.8503\n",
            "Epoch 66/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3653 - accuracy: 0.8749 - val_loss: 0.4550 - val_accuracy: 0.8478\n",
            "Epoch 67/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3724 - accuracy: 0.8732 - val_loss: 0.5017 - val_accuracy: 0.8353\n",
            "Epoch 68/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3664 - accuracy: 0.8742 - val_loss: 0.4639 - val_accuracy: 0.8438\n",
            "Epoch 69/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3542 - accuracy: 0.8830 - val_loss: 0.4728 - val_accuracy: 0.8416\n",
            "Epoch 70/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3562 - accuracy: 0.8784 - val_loss: 0.4341 - val_accuracy: 0.8562\n",
            "Epoch 71/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3716 - accuracy: 0.8726 - val_loss: 0.4420 - val_accuracy: 0.8459\n",
            "Epoch 72/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3633 - accuracy: 0.8759 - val_loss: 0.4288 - val_accuracy: 0.8569\n",
            "Epoch 73/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3512 - accuracy: 0.8795 - val_loss: 0.4504 - val_accuracy: 0.8494\n",
            "Epoch 74/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3537 - accuracy: 0.8786 - val_loss: 0.4152 - val_accuracy: 0.8566\n",
            "Epoch 75/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3457 - accuracy: 0.8849 - val_loss: 0.4649 - val_accuracy: 0.8434\n",
            "Epoch 76/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3487 - accuracy: 0.8820 - val_loss: 0.4376 - val_accuracy: 0.8553\n",
            "Epoch 77/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3447 - accuracy: 0.8821 - val_loss: 0.4208 - val_accuracy: 0.8637\n",
            "Epoch 78/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3492 - accuracy: 0.8803 - val_loss: 0.4692 - val_accuracy: 0.8466\n",
            "Epoch 79/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3421 - accuracy: 0.8808 - val_loss: 0.4265 - val_accuracy: 0.8606\n",
            "Epoch 80/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3402 - accuracy: 0.8826 - val_loss: 0.4357 - val_accuracy: 0.8597\n",
            "Epoch 81/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3430 - accuracy: 0.8818 - val_loss: 0.3881 - val_accuracy: 0.8703\n",
            "Epoch 82/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3300 - accuracy: 0.8874 - val_loss: 0.4110 - val_accuracy: 0.8653\n",
            "Epoch 83/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3283 - accuracy: 0.8866 - val_loss: 0.4441 - val_accuracy: 0.8522\n",
            "Epoch 84/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3257 - accuracy: 0.8866 - val_loss: 0.4459 - val_accuracy: 0.8575\n",
            "Epoch 85/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3306 - accuracy: 0.8859 - val_loss: 0.4055 - val_accuracy: 0.8691\n",
            "Epoch 86/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3237 - accuracy: 0.8907 - val_loss: 0.4121 - val_accuracy: 0.8694\n",
            "Epoch 87/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3299 - accuracy: 0.8902 - val_loss: 0.4167 - val_accuracy: 0.8619\n",
            "Epoch 88/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3160 - accuracy: 0.8919 - val_loss: 0.4215 - val_accuracy: 0.8628\n",
            "Epoch 89/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3141 - accuracy: 0.8935 - val_loss: 0.4711 - val_accuracy: 0.8528\n",
            "Epoch 90/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3267 - accuracy: 0.8888 - val_loss: 0.3882 - val_accuracy: 0.8706\n",
            "Epoch 91/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3167 - accuracy: 0.8895 - val_loss: 0.4033 - val_accuracy: 0.8694\n",
            "Epoch 92/100\n",
            "546/546 [==============================] - 11s 19ms/step - loss: 0.3084 - accuracy: 0.8952 - val_loss: 0.4851 - val_accuracy: 0.8450\n",
            "Epoch 93/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3100 - accuracy: 0.8932 - val_loss: 0.4404 - val_accuracy: 0.8584\n",
            "Epoch 94/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3095 - accuracy: 0.8953 - val_loss: 0.4344 - val_accuracy: 0.8553\n",
            "Epoch 95/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.2977 - accuracy: 0.8975 - val_loss: 0.3851 - val_accuracy: 0.8769\n",
            "Epoch 96/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3111 - accuracy: 0.8917 - val_loss: 0.3875 - val_accuracy: 0.8759\n",
            "Epoch 97/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3020 - accuracy: 0.8952 - val_loss: 0.4104 - val_accuracy: 0.8641\n",
            "Epoch 98/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3077 - accuracy: 0.8926 - val_loss: 0.4749 - val_accuracy: 0.8481\n",
            "Epoch 99/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3118 - accuracy: 0.8921 - val_loss: 0.4134 - val_accuracy: 0.8631\n",
            "Epoch 100/100\n",
            "546/546 [==============================] - 10s 19ms/step - loss: 0.3021 - accuracy: 0.8966 - val_loss: 0.4421 - val_accuracy: 0.8575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiJw1dZEwFCh",
        "outputId": "46b95d2e-886e-407c-dd43-cd0f60568d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Model evaluation \n",
        "test_acc = model6.evaluate(x_test,y_test)\n",
        "print('Test accuracy of the novel model is: ', test_acc[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.8607\n",
            "Test accuracy of the novel model is:  0.8607000112533569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXPntRd3YVv"
      },
      "source": [
        "'''\n",
        "Summary of the overall model: \n",
        "\n",
        "The objective is to develop a model architecture for cifar10 and implementing it to achieve the highest test accuracy for cifar10 dataset.\n",
        "\n",
        "Similar to Resnet I have used one convolutional2D layer followed by batchnormalisation, at 6 instances in the model. In the original resnet maxpooling2D layer occurs after \n",
        "the batchnormalisation. In the novel model I have tried using maxpooling layer with a pool size of 2, after bacthnormalising layer in the 2nd convolutional layer of a block. \n",
        "Maxpooling2D layer is more accurate than the averagepooling layer\n",
        "\n",
        "A traditional convolutional neural network for image classification, will use pooling layers to downsample input images. \n",
        "For example, an average pooling or max pooling layer will reduce the feature maps from a convolutional by half on each dimension, \n",
        "resulting in an output that is one quarter the area of the input.\n",
        "\n",
        "Convolutional layers themselves also perform a form of downsampling by applying each filter across the input images or feature maps,\n",
        "the resulting activations are an output feature map that is smaller because of the border effects. Often padding is used to counter \n",
        "this effect.\n",
        "\n",
        "\n",
        "Also, I have used lookahead optimiser as Adam inner optimiser. Lookahead improves the learning stability and lowers the variance of its inner optimizer Adam,\n",
        "Lookahead however maintains two sets of weights and then interpolates between them which in effect it allows a faster set of weights to ‘look ahead’ or explore\n",
        "while the slower weights stay behind to provide longer term stability.The result is reduced variance during training, and much less sensitivity to sub-optimal \n",
        "hyper-parameters and reduces the need for extensive hyper-parameter tuning. This is done while achieving faster convergence. \n",
        "\n",
        "\n",
        "Model architecture:\n",
        "The input layer is a convolutional2D layer and the output layer is a fully connected dense layer with 10 nodes and softmax activation. \n",
        "\n",
        "\n",
        "Convolutional layers: 8\n",
        "Maxepooling layers: 4\n",
        "Dropout layers: 4\n",
        "Batchnormalisation layer: 9\n",
        "Fully connected dense layer with relu activation: 2 \n",
        "\n",
        "\n",
        "Let us explore the layers in detail:\n",
        "\n",
        "Input: Image of dimensions (32,32, 3).\n",
        "Convolution Layer Conv1: The filter size of 32\n",
        "Conv1-1: 32 filters\n",
        "Conv1-2: 32 filters and Maxpooling\n",
        "Image dimensions: (16,16)\n",
        "\n",
        "\n",
        "Convolution layer Conv2: Double the filter size to 64\n",
        "Input Image dimensions: (16,16)\n",
        "Conv2-1: 64 filters\n",
        "Conv2-2: 64 filters and Maxpooling\n",
        "\n",
        "upsampling layer : \n",
        "\n",
        "\n",
        "Convolution Layer Conv3: Double the filter size to 128\n",
        "Input Image dimensions: (8,8)\n",
        "Conv3-1: 128 filters\n",
        "Conv3-2: 128 filters and Maxpooling\n",
        "\n",
        "\n",
        "Convolution Layer Conv3: Double the filter size to 256\n",
        "Input Image dimensions: (4,4)\n",
        "Conv3-1: 256 filters\n",
        "Conv3-2: 256 filters and Maxpooling\n",
        "\n",
        "\n",
        "Flatten layer creates a feature vector of (1,1024)\n",
        "\n",
        "The output dimensions here are (2,2). At this point, we flatten the output of this layer to generate a feature vector\n",
        "Fully Connected/Dense: 128 nodes, generating a feature vector of size(1, 128)\n",
        "Fully Connected /Dense: 10 nodes (Output layer), generating 10 channels for 10 classes. This is then passed on to a Softmax activation function\n",
        "\n",
        "\n",
        "Benefits of the model: \n",
        "The model uses batchnormalising layer followed by convolutional2D layer, as it has severl advantages such as reducing internal covariant shift, reducing the dependence of gradients on the scale of the parameters or their initial values.\n",
        "Regularizes the model and reduces the need for dropout, photometric distortions, local response normalization and other regularization techniques.\n",
        "\n",
        "I have avoided the use of strides in the convolutional2D layers as it can cause loss of information. \n",
        "If a pattern is visible most strongly on a position that is skipped, that information is lossed.\n",
        "To avoid this, usually max pooling layers are used to shrink the size of activation maps. \n",
        "\n",
        "Usage of upsampling2D layer followed by the convolutional 2D layer significantly improves the model test accuracy. And in some instanced it is regarded that it is \n",
        "similar to the Conv2DTranspose. \n",
        "\n",
        "The model is optimised by the usage of Lookahead optimiser and adam as the inner optimiser. Data augmentation is used in training data. \n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK4WG-0-1wMP",
        "outputId": "66b44927-c014-4653-c714-5026bafd5d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        " # summarize history for loss  and accuracy\n",
        "\n",
        "\n",
        "plt.subplot(212)  \n",
        "plt.plot(history6.history['accuracy'])  \n",
        "plt.plot(history6.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()\n",
        "  \n",
        "plt.subplot(212)  \n",
        "plt.plot(history6.history['loss'])  \n",
        "plt.plot(history6.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show() "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}